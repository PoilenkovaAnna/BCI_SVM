# Распознавание мысленно произносимых фонем по данным ЭЭГ и ЭМГ 

В данной работе рассматривается задача классификации мысленно произносимых фонем русского языка. Для решения этой задачи используются данные, полученные с электродов электроэнцефалографа, которые расположены на поверхности головы, а также значения сигналов электромиографа, снятых в области, отвечающей за речь. Основная цель исследования заключается в разработке алгоритма для эффективного распознавания фонем русского языка на основе данных, полученных с электроэнцефалографии и электромиографа в области речи. В работе рассматриваются различные методы машинного обучения и нейросетевые подходы, которые применяются для решения данной задачи. Мы также использовали модель с методом опорных векторов (SVC) с подобранными гиперпараметрами. Результаты наших экспериментов показали, что с использованием данной модели мы достигли точности в среднем 23.9% на данных электроэнцефалографии и 18.8% при объединении данных электроэнцефалографии и электромиографа.



## 1. Извлечение признаков

В качестве метода выделения признаков лучше всего себя показало четырехуровневое дискретное вейвлет-преобразование ( Discrete Wavelet Transform, DWT) с использованием вельвета Добеши и с последующим извлечением коэффициентов авторегрессии из низкочастотных сигналов. Двойной рамкой обозначены сигналы, для которых находят авторегрессионные коэффициенты, а также медианное абсолютное отклонение ( Median absolute deviation, MAD ) и среднеквадратичное отклонение ( Standard deviation, STD ). 

<img width="394" alt="image" src="https://github.com/PoilenkovaAnna/BCI_SVM/assets/55884243/2f4a47e0-4fd4-43c4-aac6-2f9ff4512bb8">

в файле: **phonemes_ARIMA.ipynb** формируются CVS файлы для дальнейшей классификации

Для этого: 

1.  Открываются данные EEG и EMG
2.  Запись EEG и EMG нарезается на сегменты с помощью введенных временых меток во время эксперемента
    ```
    def extract_strict_sectors(edf, sector_length = 600 ):
    ```
3.  К каждому сегменту применятся четырехуровневое дискретное вейвлет-преобразование (DWT) и из полученных сигналов извлекаем с помощью авторегресионной модели коэффициеты, MAD и STD
   ```
   (data, coeff_d) = pywt.dwt(data, waveletname)
   AutoRegRes = AutoReg(data, 3).fit()
   MAD = stats.median_abs_deviation(data)
   std = np.std(data)
   ```

Файлы признакнаков расположены в папке **Data_EEG+EMG_csv**

## 2. Классификация 
в файле: **classification_SVM.ipynb** 

1.  Открываются файлы CVS c признаками из папки **Data_EEG+EMG_csv**
2.  Обучение модели 
3.  Проверка модели с помощью метода псевдовыборок ( метод Bootstrap )

